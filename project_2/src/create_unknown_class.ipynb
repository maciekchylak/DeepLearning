{"cells":[{"cell_type":"markdown","source":"## Create files from the unknown class","metadata":{"cell_id":"7f66da87101a4128af8ea2e52961f656","formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"import os\nimport warnings\n\nimport librosa\nimport numpy as np\nimport soundfile as sf\n\nimport scipy.io.wavfile as wav\nfrom scipy.signal import resample\nfrom keras.utils import pad_sequences\n\nimport random\nnp.random.seed(0)\n\nimport librosa\nimport soundfile as sf\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nAUDIO_FORMAT = \"WAV\"","metadata":{"cell_id":"7c8e85e7427b48ae9daaddca336cc872","source_hash":"18d48abf","execution_start":1682242517394,"execution_millis":18387,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2023-04-23 09:35:17.443045: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-04-23 09:35:18.647052: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-04-23 09:35:18.742555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-04-23 09:35:18.742576: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-04-23 09:35:19.162828: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-04-23 09:35:28.769800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-04-23 09:35:28.769898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-04-23 09:35:28.769911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Unknown from other recordings","metadata":{"cell_id":"a178c32481c944d9a59b894c475b13b9","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"#read data that are not specific classes in test\ntrain_audio_path_without_silence = '/work/deep_learning/project_2/train/audio_without_silence'\n\nclass_names = []\ntest_classes= ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'silence_background_noise']\n\nfor file in os.listdir(train_audio_path_without_silence):\n    d = os.path.join(train_audio_path_without_silence, file)\n    if os.path.isdir(d):\n        new_name=str(os.path.basename(d))\n        if new_name not in test_classes:\n            class_names.append(str(os.path.basename(d)))\n\n\nnew_sample_rate = 8000\nnumber_of_cepstral_coefficients = 13\n\nclass_list = []\nsample_list = []\n\nfor class_name in class_names:\n    class_path_without_silence = f\"{train_audio_path_without_silence}/{class_name}\"\n    number=0\n    \n    class_files = [f for f in os.listdir(class_path_without_silence) \n        if os.path.isfile(os.path.join(class_path_without_silence, f))]\n    for class_file in class_files:\n        if number>50:\n            print(f'class: {class_name}, number: {number}')\n            break\n        try:\n            # read wavfile\n            sample_rate, sample = wav.read(f\"{class_path_without_silence}/{class_file}\")\n\n            # resample 16k -> 8k\n            sample = resample(sample, int(new_sample_rate/sample_rate * sample.shape[0]))\n\n            # padding\n            sample = pad_sequences([sample], maxlen=8000, dtype='float', padding='post', truncating='post', value=0.0)\n\n            # normalization\n            sample = sample / np.max(np.abs(sample))\n       \n            class_list.append(class_name)\n            sample_list.append(sample)\n            number+=1\n        except ValueError:\n            pass\n","metadata":{"cell_id":"ff1a008ed5144dba9de63c3dbcd82ddc","source_hash":"c4a55fd4","execution_start":1682243831562,"execution_millis":20634,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"class: eight, number: 51\nclass: cat, number: 51\nclass: house, number: 51\nclass: sheila, number: 51\nclass: four, number: 51\nclass: six, number: 51\nclass: seven, number: 51\nclass: one, number: 51\nclass: five, number: 51\nclass: happy, number: 51\nclass: bird, number: 51\nclass: bed, number: 51\nclass: nine, number: 51\nclass: marvin, number: 51\nclass: dog, number: 51\n771\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"#mix randomly some of the recordings\n\nsample_mix_list=[]\nrate_mix_list=[]\n\nfor i in range(1000):\n    num1=np.random.randint(0,len(sample_list))\n    num2=np.random.randint(0,len(sample_list))\n    num3=np.random.randint(0,len(sample_list))\n\n    mix_1= np.random.randint(0,100)/100\n    mix_2= np.random.randint(0,100)/100\n    mix_3=1-mix_1-mix_2\n\n    sample_mix= mix_1*sample_list[num1][0]+mix_2*sample_list[num2][0]+mix_3*sample_list[num3][0]\n\n    sample_mix_list.append(sample_mix)\n    rate_mix_list.append(8000)\n","metadata":{"cell_id":"41a26d5ae5ee4d3bb94d926929b90074","source_hash":"ac7921aa","execution_start":1682244157180,"execution_millis":128,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":49},{"cell_type":"code","source":"for i in range (len(rate_list)):\n    sf.write(f\".{train_audio_path_without_silence}/unknown/unknown_{i}.wav\", sample_mix_list[i], rate_list[i])","metadata":{"cell_id":"b99d551975f64f5f88ede1aae406ace2","source_hash":"5e81e7c","execution_start":1682379098983,"execution_millis":33,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{"cell_id":"9bb17ea87bbd427286d6c40503ef4f90","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6ec8773e-c89e-4114-ab03-f7a026dc9b15' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"9c867211c77041eaba513dd3350b68b7","deepnote_execution_queue":[]}}